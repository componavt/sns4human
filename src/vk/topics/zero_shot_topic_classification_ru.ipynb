{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMBOM7X2Iatp22UcKB1D/Ci",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/sns4human/blob/main/src/vk/topics/zero_shot_topic_classification_ru.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üîçüìö Zero-Shot Multilingual Topic Classifier\n",
        "\n",
        "üéØ **Goal**: Automatically assign one of 24 expert-defined topics to thousands of short social media posts ‚Äî without any fine-tuning!\n",
        "\n",
        "ü§ñ **Model**: [`joeddav/xlm-roberta-large-xnli`](https://huggingface.co/joeddav/xlm-roberta-large-xnli) (based on XLM-RoBERTa)\n",
        "\n",
        "üóÇ **Input**: CSV file with columns:\n",
        "- `text` ‚Äî the post content\n",
        "- `topic` ‚Äî the expert-assigned label\n",
        "\n",
        "üìà **Output**:\n",
        "- `classified_posts.csv` with predicted topic and confidence score\n",
        "- Evaluation metrics: `accuracy`, `precision`, `recall`, `F1-score`\n",
        "\n",
        "üß™ Ideal for: fast prototyping of topic classification in Russian and other languages using Hugging Face's zero-shot pipeline.\n",
        "\n",
        "‚ö°Ô∏è Tip: Batch-processing enabled for efficient GPU utilization."
      ],
      "metadata": {
        "id": "SYKUhwCYWCKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# topics are indicated by an expert for each social network post\n",
        "filename = '512_posts_24_topics.csv'"
      ],
      "metadata": {
        "id": "GNYG0aqgO9YT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJUb8UuvL8Ai",
        "outputId": "912389d8-aaf6-4cad-a167-d7389cb42c4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at joeddav/xlm-roberta-large-xnli were not used when initializing XLMRobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total posts after filtering: 463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Classifying posts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [10:13<00:00, 10.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report (Zero-Shot vs Expert Labels):\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "         –≠–ø–æ—Å_–ö–∞–ª–µ–≤–∞–ª–∞       0.22      0.33      0.27         6\n",
            "       –±–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ       0.37      0.54      0.44        13\n",
            "                 –≤–µ–ø—Å—ã       0.33      0.31      0.32        13\n",
            "                 –≤–æ–π–Ω–∞       0.62      0.45      0.53        11\n",
            "              –≤—ã—Å—Ç–∞–≤–∫–∞       0.55      0.82      0.65        22\n",
            "–¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –∏ —é–±–∏–ª–µ–π       0.65      0.57      0.60        23\n",
            "             –µ–¥–∞ –∫—É—Ö–Ω—è       0.80      0.25      0.38        16\n",
            "       –∫–∞—Ä–µ–ª—å—Å–∫–∏–π —è–∑—ã–∫       0.23      0.68      0.34        19\n",
            "               –∫–æ–Ω–∫—É—Ä—Å       0.29      0.55      0.38        20\n",
            "            –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞       0.15      0.17      0.16        12\n",
            "   –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –ø—Ä–æ–µ–∫—Ç—ã       0.25      0.08      0.12        48\n",
            "      –º—É–∑–µ–π. —ç–∫—Å–∫—É—Ä—Å–∏—è       0.17      0.05      0.07        22\n",
            "                –º—É–∑—ã–∫–∞       0.77      0.53      0.62        19\n",
            "           –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ       0.33      0.15      0.21        13\n",
            "                –ø–æ—ç–∑–∏—è       0.00      0.00      0.00         6\n",
            "              –ø—Ä–∞–∑–¥–Ω–∏–∫       0.36      0.53      0.43        30\n",
            "               –ø—Ä–∏—Ä–æ–¥–∞       0.47      0.44      0.46        18\n",
            "                 –ø—É—Å—Ç–æ       0.00      0.00      0.00         0\n",
            "      —Å–æ—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ñ–µ—Ä–∞       0.46      0.28      0.35        46\n",
            "              —Ç—Ä–∞–¥–∏—Ü–∏—è       0.18      0.08      0.11        24\n",
            "             —Ñ–µ—Å—Ç–∏–≤–∞–ª—å       0.58      0.50      0.54        22\n",
            "              —Ñ–æ–ª—å–∫–ª–æ—Ä       0.33      0.56      0.42         9\n",
            "          —ç—Ç–Ω–æ–∫—É–ª—å—Ç—É—Ä–∞       0.03      0.17      0.05         6\n",
            "                  —è–∑—ã–∫       0.57      0.36      0.44        45\n",
            "\n",
            "              accuracy                           0.36       463\n",
            "             macro avg       0.36      0.35      0.33       463\n",
            "          weighted avg       0.41      0.36      0.36       463\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from io import StringIO\n",
        "import requests\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load zero-shot classification pipeline with multilingual support\n",
        "classifier = pipeline(\"zero-shot-classification\", model=\"joeddav/xlm-roberta-large-xnli\")\n",
        "\n",
        "# Load texts with 'text' and 'topic' columns\n",
        "response = requests.get(f'https://raw.githubusercontent.com/componavt/sns4human/refs/heads/main/data/vk/topics/{filename}')\n",
        "df = pd.read_csv(StringIO(response.text), delimiter=',', encoding='utf-8')\n",
        "\n",
        "# Remove unassigned topic posts\n",
        "df = df[df['topic'].str.lower() != '–ø—É—Å—Ç–æ'].copy()\n",
        "\n",
        "print(f\"Total posts after filtering: {len(df)}\")\n",
        "\n",
        "texts       = df['text'].tolist()\n",
        "true_labels = df['topic'].tolist()\n",
        "\n",
        "# List of 24 topic labels defined by the expert\n",
        "topic_labels = [\n",
        "    \"–≠–ø–æ—Å_–ö–∞–ª–µ–≤–∞–ª–∞\", \"–±–ª–∞–≥–æ—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ\", \"–≤–µ–ø—Å—ã\", \"–≤–æ–π–Ω–∞\", \"–≤—ã—Å—Ç–∞–≤–∫–∞\",\n",
        "    \"–¥–µ–Ω—å —Ä–æ–∂–¥–µ–Ω–∏—è –∏ —é–±–∏–ª–µ–π\", \"–µ–¥–∞ –∫—É—Ö–Ω—è\", \"–∫–∞—Ä–µ–ª—å—Å–∫–∏–π —è–∑—ã–∫\", \"–∫–æ–Ω–∫—É—Ä—Å\",\n",
        "    \"–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞\", \"–º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è –ø—Ä–æ–µ–∫—Ç—ã\", \"–º—É–∑–µ–π. —ç–∫—Å–∫—É—Ä—Å–∏—è\", \"–º—É–∑—ã–∫–∞\",\n",
        "    \"–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ\", \"–ø–æ—ç–∑–∏—è\", \"–ø—Ä–∞–∑–¥–Ω–∏–∫\", \"–ø—Ä–∏—Ä–æ–¥–∞\", \"—Å–æ—Ü–∏–∞–ª—å–Ω–∞—è —Å—Ñ–µ—Ä–∞\",\n",
        "    \"—Ç—Ä–∞–¥–∏—Ü–∏—è\", \"—Ñ–µ—Å—Ç–∏–≤–∞–ª—å\", \"—Ñ–æ–ª—å–∫–ª–æ—Ä\", \"—ç—Ç–Ω–æ–∫—É–ª—å—Ç—É—Ä–∞\", \"—è–∑—ã–∫\", \"–ø—É—Å—Ç–æ\"\n",
        "]\n",
        "\n",
        "# Store results\n",
        "results = []\n",
        "predicted_labels = []\n",
        "\n",
        "# Batch processing\n",
        "batch_size = 8\n",
        "for i in tqdm(range(0, len(texts), batch_size), desc=\"Classifying posts\"):\n",
        "    batch = texts[i:i+batch_size]\n",
        "    outputs = classifier(batch, topic_labels, multi_label=False)\n",
        "    if isinstance(outputs, dict):  # if only one item\n",
        "        outputs = [outputs]\n",
        "    for output in outputs:\n",
        "        top_label = output['labels'][0]\n",
        "        confidence = output['scores'][0]\n",
        "        predicted_labels.append(top_label)\n",
        "        results.append({\n",
        "            \"text\": output['sequence'],\n",
        "            \"predicted_topic\": top_label,\n",
        "            \"confidence\": confidence\n",
        "        })\n",
        "\n",
        "# Save to CSV\n",
        "result_df = pd.DataFrame(results)\n",
        "result_df['true_topic'] = true_labels\n",
        "result_df.to_csv(\"classified_posts.csv\", index=False, encoding=\"utf-8\")\n",
        "\n",
        "# Evaluate accuracy\n",
        "print(\"\\nClassification Report (Zero-Shot vs Expert Labels):\")\n",
        "print(classification_report(true_labels, predicted_labels, zero_division=0))"
      ]
    }
  ]
}