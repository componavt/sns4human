{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNc+dU+P68VRmLJQjoVuyUm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/sns4human/blob/main/src/vk/topics/accuracy/xlm-roberta_accuracy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üßÆ xlm-roberta Accuracy: {accuracy}%  \n",
        "(Tested on {N} expert-labeled posts)  "
      ],
      "metadata": {
        "id": "HT0oibt5xB4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load expert-labeled dataset\n",
        "file_expert_labeled = \"512_posts_24_topics.csv\"\n",
        "\n",
        "# Define model path (Hugging Face repo)\n",
        "model_repo = \"componavt/xlm-roberta-base-topic-classification-2025\""
      ],
      "metadata": {
        "id": "Xupcx1PrrBGY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install -U transformers pandas scikit-learn\n",
        "\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from io import StringIO\n",
        "import requests\n",
        "\n",
        "# ========== 1. Load expert-labeled dataset ==========\n",
        "url = f'https://raw.githubusercontent.com/componavt/sns4human/refs/heads/main/data/vk/topics/{file_expert_labeled}'\n",
        "response = requests.get(url)\n",
        "df = pd.read_csv(StringIO(response.text), encoding='utf-8')\n",
        "df = df[df['topic'].str.lower() != '–ø—É—Å—Ç–æ'].copy()\n",
        "\n",
        "print(f\"Loaded {len(df)} posts with expert-labeled topics.\")\n",
        "\n",
        "# ========== 2. Prepare label encoder ==========\n",
        "unique_topics = sorted(df['topic'].unique())\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(unique_topics)\n",
        "df['true_label_id'] = label_encoder.transform(df['topic'])\n",
        "\n",
        "# ========== 3. Load model and tokenizer ==========\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_repo)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_repo)\n",
        "\n",
        "device = 0 if torch.cuda.is_available() else -1\n",
        "pipe = TextClassificationPipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=device,\n",
        "    top_k=None,\n",
        "    truncation=True,\n",
        "    max_length=512,\n",
        "    padding=True\n",
        ")\n",
        "\n",
        "# ========== 4. Run inference and compare ==========\n",
        "correct = 0\n",
        "total = len(df)\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    text = row['text']\n",
        "    true_topic = row['topic']\n",
        "    true_id = row['true_label_id']\n",
        "\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        preds = pipe(text)[0]\n",
        "        best = max(preds, key=lambda x: x['score'])\n",
        "        pred_id = int(best['label'].replace('LABEL_', ''))\n",
        "        pred_topic = label_encoder.inverse_transform([pred_id])[0]\n",
        "\n",
        "        if pred_topic == true_topic:\n",
        "            correct += 1\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error on row {idx}: {e}\")\n",
        "\n",
        "# ========== 5. Report results ==========\n",
        "accuracy = correct / total * 100\n",
        "print(f\"\\n‚úÖ Correct predictions: {correct} / {total}\")\n",
        "print(f\"üéØ Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "alv2wt8umqL5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}