# -*- coding: utf-8 -*-
"""text_preprocessing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XqkrhqFOMTHaOHrkIFAnZgk8I6u4GiYW
"""

import pandas as pd
import nltk
from nltk.tokenize import word_tokenize, sent_tokenize
import pymorphy3
import requests
import csv
import emoji
from nltk.corpus import stopwords

nltk.download('stopwords', quiet=True)
nltk.download('punkt', quiet=True)
nltk.download('punkt_tab', quiet=True)


stop_words = stopwords.words("russian")
stop_words += requests.get('https://raw.githubusercontent.com/componavt/sns4human/refs/heads/main/src/vk/nlp/RussianStopWords.txt').text.split('\n')
stop_words += requests.get('https://raw.githubusercontent.com/componavt/sns4human/refs/heads/main/src/vk/nlp/stopwords-ru.txt').text.split()

alphabet = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя-.')
morph = pymorphy3.MorphAnalyzer(lang='ru')

def process_text(text, points=False):
    sentences = sent_tokenize(text)
    processed_sentences = []

    for sentence in sentences:
        processed_parts = []

        for w in word_tokenize(sentence):
            if (len(w) == 1 or
                ":" in emoji.demojize(w) or
                not set(w.lower()).issubset(alphabet) or
                not w[0:2].lower().isalpha() or
                '\\' in w or
                '/' in w):
                continue

            res = morph.parse(w.lower())[0].normal_form
            if res and (res not in stop_words):
                processed_parts.append(res)

        if points and processed_parts:
            processed_parts[-1] += "."

        processed_sentences.append(" ".join(processed_parts))

    return " ".join(processed_sentences)