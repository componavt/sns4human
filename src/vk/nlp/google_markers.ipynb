{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKJg8ZDZ6ph32gObU0/4Z7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/sns4human/blob/main/src/vk/nlp/google_markers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Методика генерации меток тем с помощью ИПС\n"
      ],
      "metadata": {
        "id": "0Adw5-guQlPj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script generates tags for a topic represented as a set of words using the Google search engine.\n",
        "\n",
        "Этот скрипт генерирует метки для темы, представленной  в виде набора слов, используя поисковую систему Google."
      ],
      "metadata": {
        "id": "PVuCfJL5Qpid"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pymorphy3\n",
        "!pip install - q gensim\n",
        "import pymorphy3\n",
        "from gensim import  models\n",
        "import requests\n",
        "from collections import Counter\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "morph = pymorphy3.MorphAnalyzer(lang='ru')"
      ],
      "metadata": {
        "id": "wVBsLKplZT9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "API_KEY = \"ваш API KEY\"\n",
        "SEARCH_ENGINE_ID = \"ваш SEARCH_ENGINE_ID\"\n",
        "GOOGLE_API_URL = \"ваш GOOGLE_API_URL\""
      ],
      "metadata": {
        "id": "lyvcwzmwYwrS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка текста запроса"
      ],
      "metadata": {
        "id": "UZExFMkiQvOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model = models.ldamodel.LdaModel.load('res.model')\n",
        "queries = []\n",
        "for n in range(0, lda_model.num_topics):\n",
        "    queries.append(' '.join([term for term, wt in lda_model.show_topic(n)]))\n",
        "query = queries[4]\n",
        "query"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2xbw-CeORHkV",
        "outputId": "1a68dc8b-194e-4256-c18a-5b4f02a187b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'район посёлок коронавирус пневмония пациент госпитализировать исход подтвердить число инфекция'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Получение меток"
      ],
      "metadata": {
        "id": "HppijbE4UezX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from collections import Counter\n",
        "import re\n",
        "from string import punctuation\n",
        "\n",
        "query = \"район коронавирус пневмония пациент госпитализировать исход подтвердить число инфекция\"\n",
        "query_words = {word.strip().lower() for word in query.split(\" \")}\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'\\d+', '', text.lower())\n",
        "    words = re.findall(r'[а-яё]+', text)\n",
        "    return [\n",
        "        morph.parse(w)[0].normal_form\n",
        "        for w in words\n",
        "        if len(w) > 2\n",
        "    ]\n",
        "\n",
        "def extract_ngrams(documents, n_range=(2, 3), top_n=5):\n",
        "    ngrams_counter = Counter()\n",
        "\n",
        "    for doc in documents:\n",
        "        words = preprocess_text(doc)\n",
        "        for n in range(n_range[0], n_range[1] + 1):\n",
        "            ngrams_counter.update(\n",
        "                [' '.join(words[i:i+n])\n",
        "                 for i in range(len(words)-n+1)]\n",
        "            )\n",
        "    return sorted(\n",
        "        ngrams_counter.items(),\n",
        "        key=lambda x: (\n",
        "            -x[1],  # Частота\n",
        "            sum(word in x[0] for word in query_words),  # Совпадения с запросом\n",
        "            -len(x[0].split())  # Предпочтение более длинным N-граммам\n",
        "        )\n",
        "    )[:top_n]\n",
        "\n",
        "def get_search_results(query):\n",
        "    url =  GOOGLE_API_URL\n",
        "    params = {\n",
        "        \"key\": API_KEY,\n",
        "        \"cx\": SEARCH_ENGINE_ID,\n",
        "        \"q\": query,\n",
        "        \"num\": 10,\n",
        "        \"hl\": \"ru\"\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "    response.raise_for_status()\n",
        "    return response.json()\n",
        "\n",
        "try:\n",
        "    response = get_search_results(query)\n",
        "    documents = [\n",
        "        f\"{item['title']} {item.get('snippet', '')}\"\n",
        "        for item in response.get('items', [])\n",
        "    ]\n",
        "\n",
        "    top_phrases = extract_ngrams(documents, n_range=(2, 3))\n",
        "\n",
        "    print(\"Топ релевантных русских словосочетаний:\")\n",
        "    for i, (phrase, count) in enumerate(top_phrases, 1):\n",
        "        print(f\"{i}. {phrase}\")\n",
        "\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"Ошибка при выполнении запроса: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye88zmxkgTta",
        "outputId": "b5fa57e7-24b3-4561-de0e-2fc093abae2d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Топ релевантных русских словосочетаний:\n",
            "1. госпитализировать пациент\n",
            "2. случай заболевание\n",
            "3. подтвердить заражение\n",
            "4. двухсторонний пневмония\n",
            "5. число случай\n"
          ]
        }
      ]
    }
  ]
}