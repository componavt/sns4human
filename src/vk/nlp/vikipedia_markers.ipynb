{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFFuItw2VwDcXcAesNpZUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/sns4human/blob/main/src/vk/nlp/vikiperdia_markers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This script searches for articles in Russian Wikipedia by given keywords, extracts meaningful Russian words and phrases from their titles, and then outputs them as sorted labels.\n",
        "\n",
        "Этот скрипт ищет статьи в русской Википедии по заданным ключевым словам  извлекает из их заголовков осмысленные русские слова и словосочетания, а затем выводит их в виде отсортированных меток."
      ],
      "metadata": {
        "id": "OACTkk3rbRjf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-Y-kzcX_vi_-"
      },
      "outputs": [],
      "source": [
        "!pip install -q wikipedia-api nltk\n",
        "!pip install  -q pymorphy3\n",
        "import requests\n",
        "import re\n",
        "from pymorphy3 import MorphAnalyzer\n",
        "\n",
        "morph = MorphAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_russian_wikipedia_titles(query, limit=8):\n",
        "    endpoint = \"https://ru.wikipedia.org/w/api.php\"\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"list\": \"search\",\n",
        "        \"srsearch\": query,\n",
        "        \"srlimit\": limit,\n",
        "        \"srprop\": \"\",\n",
        "        \"srwhat\": \"text\",\n",
        "        \"srinfo\": \"\",\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        response = requests.get(endpoint, params=params)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        articles = data.get(\"query\", {}).get(\"search\", [])\n",
        "        return [article[\"title\"] for article in articles]\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе к Wikipedia API: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_russian_phrases(titles, morph):\n",
        "    phrases = set()\n",
        "    pos_keep = {'NOUN', 'ADJF', 'ADJS', 'VERB', 'INFN', 'PRTF', 'PRTS', 'GRND'}\n",
        "\n",
        "    for title in titles:\n",
        "        clean_title = re.sub(r'\\([^)]*\\)', '', title)\n",
        "        clean_title = re.sub(r'[^а-яёА-ЯЁ\\s-]', '', clean_title)\n",
        "        clean_title = re.sub(r'\\s+', ' ', clean_title).strip()\n",
        "\n",
        "        words = [w.strip('-').lower() for w in clean_title.split() if w.strip('-')]\n",
        "        single_words = set()\n",
        "        for word in words:\n",
        "            if len(word) < 3 or not re.fullmatch(r'[а-яё]+', word):\n",
        "                continue\n",
        "\n",
        "            parsed = morph.parse(word)[0]\n",
        "            if parsed.tag.POS in pos_keep:\n",
        "                normal_form = parsed.normal_form\n",
        "                single_words.add(normal_form)\n",
        "\n",
        "        for i in range(len(words) - 1):\n",
        "            word1, word2 = words[i], words[i+1]\n",
        "\n",
        "            if (len(word1) < 3 or len(word2) < 3 or\n",
        "                not re.fullmatch(r'[а-яё]+', word1) or\n",
        "                not re.fullmatch(r'[а-яё]+', word2)):\n",
        "                continue\n",
        "\n",
        "            parsed1 = morph.parse(word1)[0]\n",
        "            parsed2 = morph.parse(word2)[0]\n",
        "\n",
        "            if (parsed1.tag.POS == 'ADJF' and parsed2.tag.POS == 'NOUN' and\n",
        "                parsed1.tag.gender == parsed2.tag.gender and\n",
        "                parsed1.tag.number == parsed2.tag.number):\n",
        "\n",
        "                noun_norm = parsed2.inflect({'nomn'}).word if 'nomn' in parsed2.tag else parsed2.normal_form\n",
        "                adj_norm = parsed1.normal_form\n",
        "                phrases.add(f\"{adj_norm} {noun_norm}\")\n",
        "                phrases.add(f\"{word1} {word2}\")\n",
        "\n",
        "            elif (parsed1.tag.POS == 'NOUN' and parsed2.tag.POS == 'NOUN' and\n",
        "                  parsed2.tag.case == 'gent'):\n",
        "\n",
        "                first_noun = parsed1.inflect({'nomn'}).word if 'nomn' in parsed1.tag else parsed1.normal_form\n",
        "                second_noun = parsed2.normal_form\n",
        "                phrases.add(f\"{first_noun} {second_noun}\")\n",
        "                phrases.add(f\"{word1} {word2}\")\n",
        "\n",
        "        phrases.update(single_words)\n",
        "\n",
        "    return sorted(phrases, key=lambda x: (-len(x.split()), x.lower()))\n",
        "\n",
        "\n",
        "query = \"море, петроглиф, озеро, река, берег, побережье\"\n",
        "search_query = [word.strip().lower() for word in query.split(\",\")]\n",
        "search_query = ' '.join(search_query)\n",
        "titles = get_russian_wikipedia_titles(search_query)\n",
        "\n",
        "print(\"\\nНайденные заголовки статей:\")\n",
        "for i, title in enumerate(titles, 1):\n",
        "  print(f\"{i}. {title}\")\n",
        "\n",
        "phrases = extract_russian_phrases(titles, morph)\n",
        "\n",
        "print(\"\\nМетки:\")\n",
        "for phrase in phrases:\n",
        "  print(f\"- {phrase}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnxWZ5Fhvrcd",
        "outputId": "b268a152-7a58-4a83-c4b7-eed7dc6d3199"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Найденные заголовки статей:\n",
            "1. Байкал\n",
            "2. Онежские петроглифы\n",
            "3. Онежское озеро\n",
            "4. Убсу-Нур\n",
            "5. Остров Врангеля\n",
            "6. Итуруп\n",
            "7. Африка\n",
            "8. Поной\n",
            "\n",
            "Метки:\n",
            "- онежский озеро\n",
            "- онежское озеро\n",
            "- остров врангель\n",
            "- остров врангеля\n",
            "- африка\n",
            "- байкал\n",
            "- врангель\n",
            "- итуруп\n",
            "- озеро\n",
            "- онежский\n",
            "- остров\n",
            "- петроглиф\n",
            "- поной\n"
          ]
        }
      ]
    }
  ]
}
