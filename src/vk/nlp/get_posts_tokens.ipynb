{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/componavt/sns4human/blob/main/src/vk/nlp/get_posts_tokens.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PO6yySLtgsh2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "!pip install -U pymorphy3\n",
        "import pymorphy3\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('punkt_tab', quiet=True)\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words(\"russian\")\n",
        "alphabet = set('абвгдеёжзийклмнопрстуфхцчшщъыьэюя-')\n",
        "morph = pymorphy3.MorphAnalyzer(lang='ru')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjsktO3-kRBW"
      },
      "outputs": [],
      "source": [
        "domains = ['rk_nationalmuseum','olonmus','museum_ptz','echo_association','domderevnivoknavolok']\n",
        "\n",
        "df = pd.concat([pd.read_csv('https://raw.githubusercontent.com/componavt/sns4human/refs/heads/main/data/vk/posts/' + domain +'.csv', usecols = ['text','date']) for domain in domains], ignore_index=True)\n",
        "df = df[df['text'].notna() & (df['text'].apply(lambda x: isinstance(x, str)))]\n",
        "df = df.reset_index()\n",
        "df = df.drop(columns=['index'])\n",
        "\n",
        "\n",
        "def process_text(text):\n",
        "    check_hash = False\n",
        "    processed_parts = []\n",
        "    for w in nltk.word_tokenize(text):\n",
        "      if len(w) == 1:\n",
        "        continue\n",
        "      if w == '#':\n",
        "          check_hash = True\n",
        "          continue\n",
        "      if check_hash:\n",
        "          check_hash = False\n",
        "          continue\n",
        "      w_tag = morph.parse(w.strip())[0].tag\n",
        "      if   'Surn' in w_tag or 'Name' in w_tag or 'Patr' in w_tag:\n",
        "         continue\n",
        "      if set(w.lower()).issubset(alphabet):\n",
        "        if w.isalpha() and w.lower():\n",
        "          if w.isupper() and len(w) <= 3:\n",
        "              processed_parts.append(w)\n",
        "          else:\n",
        "              res = morph.parse(w.lower())[0].normal_form\n",
        "              if res not in stop_words:\n",
        "                  processed_parts.append(res)\n",
        "    result = ' '.join(processed_parts)\n",
        "    return str(result)\n",
        "\n",
        "df['tokens'] = df['text'].apply(lambda x: process_text(x))\n",
        "df_tokens = pd.concat([df['tokens'], df['date']], axis=1, keys=['tokens', 'date'])\n",
        "\n",
        "df_tokens.to_csv('tokens.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMu/KDSd2AO5RG/yfKJRgA7",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}